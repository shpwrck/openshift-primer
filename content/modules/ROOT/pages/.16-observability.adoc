= Observability

Observability is the ability to measure the internal state of a system based on the data it produces—such as metrics and logs. OpenShift provides built-in support for monitoring and logging user workloads through the OpenShift Console and CLI.

== User Workload Monitoring

OpenShift provides Prometheus-based monitoring for user-deployed applications in addition to platform components. This feature is **opt-in** and must be enabled explicitly.

=== Enabling Monitoring

To enable user workload monitoring:

. Create or modify the `cluster-monitoring-config` ConfigMap in the `openshift-monitoring` namespace:

[source,yaml,role=execute]
----
apiVersion: v1
kind: ConfigMap
metadata:
  name: cluster-monitoring-config
  namespace: openshift-monitoring
data:
  config.yaml: |
    enableUserWorkload: true
----

. Apply the config:
+
[source,sh,role=execute]
----
oc apply -f cluster-monitoring-config.yaml
----

. Wait a few moments for the `openshift-user-workload-monitoring` namespace to appear.

=== Exposing Metrics in a Pod

To expose metrics:

1. Your application must serve Prometheus-formatted metrics on an HTTP endpoint (e.g., `/metrics`).
2. Annotate the `Service` to be scraped:

[source,yaml,role=execute]
----
metadata:
  annotations:
    prometheus.io/scrape: 'true'
    prometheus.io/port: '8080'
    prometheus.io/path: '/metrics'
----

=== Exercise: Monitor a Sample App

. Deploy an app that exposes `/metrics` (e.g., Prometheus example apps).
. Annotate the service.
. Visit *Observe → Metrics* in the OpenShift web console.
. Use the query bar to explore your metrics.

== User Workload Logging

OpenShift can collect logs from containers and forward them to a central logging stack. Logs are collected using the **Collector** (e.g., Fluentd or Vector), stored in **Loki** or **Elasticsearch**, and visualized through **Kibana** or **Grafana Loki UI**.

This is typically enabled through the **OpenShift Logging Operator**.

=== Enabling Logging

. Install the **OpenShift Logging** and **Elasticsearch Operators** (or Loki Operator for Loki stack).
. Create a `ClusterLogging` custom resource to define the log collection pipeline:

[source,yaml,role=execute]
----
apiVersion: "logging.openshift.io/v1"
kind: ClusterLogging
metadata:
  name: instance
  namespace: openshift-logging
spec:
  collection:
    logs:
      type: fluentd
  logStore:
    type: loki
  visualization:
    type: grafana
----
[start=3]
. Logs for user workloads in the cluster are collected automatically once configured.

=== Viewing Logs

You can view logs in two main ways:

* **Web Console**: Go to *Observe → Logs*
* **CLI**: View logs per pod using:
+
[source,sh,role=execute]
----
oc logs "pod-name"
----

=== Exercise: View Logs

. Deploy any pod (e.g., `nginx`).
. Use `oc logs` to view its output.
. Navigate to the *Logs* section in the web console and filter by project or container.
. Optionally, write a custom message to stdout and confirm it appears in the logs.
